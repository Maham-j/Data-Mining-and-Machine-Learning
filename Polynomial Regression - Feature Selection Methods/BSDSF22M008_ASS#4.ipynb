{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd03bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   R-squared:                       0.976\n",
      "Model:                            OLS   Adj. R-squared:                  0.975\n",
      "Method:                 Least Squares   F-statistic:                     1579.\n",
      "Date:                Mon, 10 Mar 2025   Prob (F-statistic):               0.00\n",
      "Time:                        23:33:50   Log-Likelihood:                -2995.6\n",
      "No. Observations:                 800   AIC:                             6033.\n",
      "Df Residuals:                     779   BIC:                             6132.\n",
      "Df Model:                          20                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -0.9013      0.703     -1.283      0.200      -2.281       0.478\n",
      "Feature_1              27.8486      0.394     70.634      0.000      27.075      28.623\n",
      "Feature_2              45.9141      0.367    124.960      0.000      45.193      46.635\n",
      "Feature_3              16.6843      0.370     45.141      0.000      15.959      17.410\n",
      "Feature_4              24.5561      0.365     67.252      0.000      23.839      25.273\n",
      "Feature_5              19.1143      0.362     52.771      0.000      18.403      19.825\n",
      "Feature_1^2            -0.0509      0.323     -0.158      0.875      -0.685       0.583\n",
      "Feature_1 Feature_2     0.2068      0.390      0.530      0.596      -0.559       0.973\n",
      "Feature_1 Feature_3    -0.3412      0.386     -0.885      0.377      -1.098       0.416\n",
      "Feature_1 Feature_4    -0.6655      0.388     -1.716      0.087      -1.427       0.096\n",
      "Feature_1 Feature_5    -0.6101      0.388     -1.572      0.116      -1.372       0.152\n",
      "Feature_2^2            -0.0022      0.259     -0.009      0.993      -0.511       0.507\n",
      "Feature_2 Feature_3     0.2375      0.390      0.608      0.543      -0.529       1.004\n",
      "Feature_2 Feature_4    -0.3185      0.372     -0.856      0.392      -1.049       0.412\n",
      "Feature_2 Feature_5     0.3344      0.380      0.880      0.379      -0.412       1.080\n",
      "Feature_3^2             0.0848      0.250      0.340      0.734      -0.405       0.575\n",
      "Feature_3 Feature_4     0.2180      0.362      0.603      0.547      -0.492       0.928\n",
      "Feature_3 Feature_5     0.1124      0.362      0.310      0.756      -0.599       0.823\n",
      "Feature_4^2             0.1385      0.246      0.564      0.573      -0.344       0.621\n",
      "Feature_4 Feature_5     0.2673      0.376      0.711      0.478      -0.471       1.006\n",
      "Feature_5^2             0.0208      0.262      0.079      0.937      -0.494       0.536\n",
      "==============================================================================\n",
      "Omnibus:                        2.269   Durbin-Watson:                   2.031\n",
      "Prob(Omnibus):                  0.322   Jarque-Bera (JB):                2.291\n",
      "Skew:                          -0.041   Prob(JB):                        0.318\n",
      "Kurtosis:                       3.249   Cond. No.                         5.66\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 Target   R-squared (uncentered):                   0.976\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.975\n",
      "Method:                 Least Squares   F-statistic:                              6337.\n",
      "Date:                Mon, 10 Mar 2025   Prob (F-statistic):                        0.00\n",
      "Time:                        23:33:50   Log-Likelihood:                         -3002.4\n",
      "No. Observations:                 800   AIC:                                      6015.\n",
      "Df Residuals:                     795   BIC:                                      6038.\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Feature_1     27.8924      0.389     71.674      0.000      27.129      28.656\n",
      "Feature_2     45.9037      0.364    126.075      0.000      45.189      46.618\n",
      "Feature_3     16.6680      0.367     45.459      0.000      15.948      17.388\n",
      "Feature_4     24.5132      0.363     67.571      0.000      23.801      25.225\n",
      "Feature_5     19.1622      0.359     53.331      0.000      18.457      19.868\n",
      "==============================================================================\n",
      "Omnibus:                        2.018   Durbin-Watson:                   2.041\n",
      "Prob(Omnibus):                  0.365   Jarque-Bera (JB):                1.986\n",
      "Skew:                          -0.041   Prob(JB):                        0.371\n",
      "Kurtosis:                       3.230   Cond. No.                         1.11\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   R-squared:                       0.976\n",
      "Model:                            OLS   Adj. R-squared:                  0.975\n",
      "Method:                 Least Squares   F-statistic:                     6356.\n",
      "Date:                Mon, 10 Mar 2025   Prob (F-statistic):               0.00\n",
      "Time:                        23:33:51   Log-Likelihood:                -3000.7\n",
      "No. Observations:                 800   AIC:                             6013.\n",
      "Df Residuals:                     794   BIC:                             6042.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6735      0.366     -1.841      0.066      -1.392       0.045\n",
      "Feature_2     45.9030      0.364    126.262      0.000      45.189      46.617\n",
      "Feature_1     27.9145      0.389     71.804      0.000      27.151      28.678\n",
      "Feature_4     24.5330      0.362     67.698      0.000      23.822      25.244\n",
      "Feature_5     19.1595      0.359     53.403      0.000      18.455      19.864\n",
      "Feature_3     16.6588      0.366     45.498      0.000      15.940      17.378\n",
      "==============================================================================\n",
      "Omnibus:                        2.008   Durbin-Watson:                   2.050\n",
      "Prob(Omnibus):                  0.366   Jarque-Bera (JB):                1.972\n",
      "Skew:                          -0.041   Prob(JB):                        0.373\n",
      "Kurtosis:                       3.229   Cond. No.                         1.12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "X_poly, y_poly = make_regression(n_samples=1000, n_features=5, noise=10, random_state=42)\n",
    "df_poly = pd.DataFrame(X_poly, columns=[f\"Feature_{i}\" for i in range(1, 6)])\n",
    "df_poly[\"Target\"] = y_poly\n",
    "\n",
    "\n",
    "degree = 2\n",
    "poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "X_poly_transformed = poly.fit_transform(df_poly.drop(columns=[\"Target\"]))\n",
    "X_poly_df = pd.DataFrame(X_poly_transformed, columns=poly.get_feature_names_out())\n",
    "\n",
    "y = df_poly[\"Target\"]\n",
    "X = X_poly_df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "\n",
    "model_all = sm.OLS(y_train, X_train_const).fit()\n",
    "print(model_all.summary())\n",
    "\n",
    "\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    while True:\n",
    "        p_values = model.pvalues\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > significance_level:\n",
    "            feature_to_remove = p_values.idxmax()\n",
    "            X = X.drop(columns=[feature_to_remove])\n",
    "            model = sm.OLS(y, X).fit()\n",
    "        else:\n",
    "            break\n",
    "    return model, X.columns\n",
    "\n",
    "model_backward, selected_features_backward = backward_elimination(X_train, y_train)\n",
    "print(model_backward.summary())\n",
    "\n",
    "\n",
    "def forward_selection(X, y, significance_level=0.05):\n",
    "    initial_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    best_model = None\n",
    "    best_features = None\n",
    "\n",
    "    while remaining_features:\n",
    "        p_values = {}\n",
    "        for feature in remaining_features:\n",
    "            X_temp = sm.add_constant(X[initial_features + [feature]])\n",
    "            model = sm.OLS(y, X_temp).fit()\n",
    "            p_values[feature] = model.pvalues[feature]\n",
    "\n",
    "        best_feature = min(p_values, key=p_values.get)\n",
    "        if p_values[best_feature] < significance_level:\n",
    "            initial_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "            best_model = sm.OLS(y, sm.add_constant(X[initial_features])).fit()\n",
    "            best_features = initial_features[:]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return best_model, best_features\n",
    "\n",
    "model_forward, selected_features_forward = forward_selection(X_train, y_train)\n",
    "print(model_forward.summary())\n",
    "\n",
    "\n",
    "def bidirectional_selection(X, y, significance_level=0.05):\n",
    "    selected_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    best_model = None\n",
    "\n",
    "    while remaining_features:\n",
    "        # Forward step\n",
    "        p_values = {}\n",
    "        for feature in remaining_features:\n",
    "            X_temp = sm.add_constant(X[selected_features + [feature]])\n",
    "            model = sm.OLS(y, X_temp).fit()\n",
    "            p_values[feature] = model.pvalues[feature]\n",
    "        \n",
    "        best_feature = min(p_values, key=p_values.get)\n",
    "        if p_values[best_feature] < significance_level:\n",
    "            selected_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "        \n",
    "        \n",
    "        model = sm.OLS(y, sm.add_constant(X[selected_features])).fit()\n",
    "        p_values = model.pvalues.drop(\"const\", errors=\"ignore\")\n",
    "        for feature, p_value in p_values.items():\n",
    "            if p_value > significance_level:\n",
    "                selected_features.remove(feature)\n",
    "                remaining_features.append(feature)\n",
    "\n",
    "        best_model = sm.OLS(y, sm.add_constant(X[selected_features])).fit()\n",
    "    \n",
    "    return best_model, selected_features\n",
    "\n",
    "model_bidirectional, selected_features_bidirectional = bidirectional_selection(X_train, y_train)\n",
    "print(model_bidirectional.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cc380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4e935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
